{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fd9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ECE 284 Project - Team RizzNet (CE) : Krish Mehta, Aryan Devrani, Anoushka Saraswat, Kumar Divij\n",
    "# This file contains the VGG16 Model with 16x8 squeezed Conv layer, with 4-bit quantization aware training\n",
    "# This is done to implement 2-way multichannel PEs, which would require 16 inputs instead.\n",
    "# The achieved accuracy was 92%.\n",
    "# The text files are written in a slightly different manner for input.txt and weights.txt, \n",
    "# with one line containing weights for row15-row0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant_project_multichannel\"\n",
    "model = VGG16_quant_project_multi()\n",
    "#print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [100,200]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b4b40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # # This cell won't be given, but students will complete the training\n",
    "# PATH = \"result/VGG16_quant_project_multichannel/model_best.pth.tar\"\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['state_dict'])\n",
    "# device = torch.device(\"cuda\") \n",
    "\n",
    "# lr = 4e-4\n",
    "# weight_decay = 1e-4\n",
    "# epochs = 300\n",
    "# best_prec = 0\n",
    "\n",
    "# #model = nn.DataParallel(model).cuda()\n",
    "# model.cuda()\n",
    "# criterion = nn.CrossEntropyLoss().cuda()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "# #optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "# #cudnn.benchmark = True\n",
    "\n",
    "# if not os.path.exists('result'):\n",
    "#     os.makedirs('result')\n",
    "# fdir = 'result/'+str(model_name)\n",
    "# if not os.path.exists(fdir):\n",
    "#     os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "# for epoch in range(0, epochs):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "#     train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "#     # evaluate on test set\n",
    "#     print(\"Validation starts\")\n",
    "#     prec = validate(testloader, model, criterion)\n",
    "\n",
    "#     # remember best precision and save checkpoint\n",
    "#     is_best = prec > best_prec\n",
    "#     best_prec = max(prec,best_prec)\n",
    "#     print('best acc: {:1f}'.format(best_prec))\n",
    "#     save_checkpoint({\n",
    "#         'epoch': epoch + 1,\n",
    "#         'state_dict': model.state_dict(),\n",
    "#         'best_prec': best_prec,\n",
    "#         'optimizer': optimizer.state_dict(),\n",
    "#     }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entertaining-queensland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9200/10000 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant_project_multichannel/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b054bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prehook and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfe6c958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prehooked QuantConv2d(\n",
      "  16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n",
      "prehooked QuantConv2d(\n",
      "  8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "  (weight_quant): weight_quantize_fn()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## Send an image and use prehook to grab the inputs of all the QuantConv2d layers\n",
    "\n",
    "class SaveOutput:\n",
    "    def __init__(self):\n",
    "        self.outputs = []\n",
    "    def __call__(self, module, module_in):\n",
    "        self.outputs.append(module_in)\n",
    "    def clear(self):\n",
    "        self.outputs = []  \n",
    "        \n",
    "######### Save inputs from selected layer ##########\n",
    "save_output = SaveOutput()\n",
    "\n",
    "# print(model.features[27])\n",
    "\n",
    "# model.features[27].register_forward_pre_hook(save_output);\n",
    "\n",
    "i=0\n",
    "for layer in model.modules():\n",
    "\n",
    "    if isinstance(layer, nn.Conv2d):\n",
    "        if(i==8 or i==9):\n",
    "            print(\"prehooked\", layer)\n",
    "            layer.register_forward_pre_hook(save_output)       \n",
    "        i=i+1;\n",
    "###################################################\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.to(device)\n",
    "out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c104e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_bit = 4\n",
    "weight_q = model.features[27].weight_q   #quantized weights for 8x8 layer\n",
    "w_alpha = model.features[27].weight_quant.wgt_alpha\n",
    "w_delta = w_alpha/(2**(w_bit-1) - 1)\n",
    "weight_int = weight_q/w_delta\n",
    "#print(weight_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "367a7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get input activations for 27th layer, it is the 8th prehooked layer in save_output\n",
    "x_bit = 4\n",
    "x = save_output.outputs[0][0]\n",
    "x_alpha = model.features[27].act_alpha\n",
    "x_delta = x_alpha/(2**x_bit - 1)\n",
    "act_quant_fn = act_quantization(x_bit)\n",
    "x_q = act_quant_fn(x, x_alpha)\n",
    "\n",
    "x_int = x_q/x_delta\n",
    "#print(x_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "022b5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining forward pass convolution through the 27th layer\n",
    "conv_int = torch.nn.Conv2d(in_channels = 16, out_channels = 8, kernel_size = 3, padding = 1, bias = False)\n",
    "conv_int.weight = torch.nn.parameter.Parameter(weight_int)\n",
    "output_int = conv_int(x_int)\n",
    "output_recovered = output_int * x_delta * w_delta\n",
    "#print(output_recovered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The reference output is the prehooked input to the 28th layer, or the 9th prehooked layer\n",
    "psum_recovered = model.features[28](output_recovered)            # 28th layer is ReLu operation\n",
    "difference = abs(save_output.outputs[1][0] - psum_recovered)\n",
    "print(difference.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64583138",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## For multi-channel PE, x_pad is sized for 16 input channels\n",
    "\n",
    "######## Padding before Convolution #######\n",
    "x_pad = torch.zeros(128, 16, 6, 6).cuda()\n",
    "# a_pad.size() = [64, 32+2pad, 32+2pad]\n",
    "x_pad[ : ,  :, 1:5, 1:5] = x_int.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74a5cc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 36])\n"
     ]
    }
   ],
   "source": [
    "X = x_pad[0] \n",
    "X = torch.reshape(X, (X.size(0), -1))\n",
    "print(X.size())\n",
    "\n",
    "####### Instead of indexing from row7.....row0 we now have row16.......row0\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('input.txt', 'w') #write to file\n",
    "file.write('#time0row15[msb-lsb],time0row6[msb-lst],....,time0row0[msb-lst]#\\n')\n",
    "file.write('#time1row15[msb-lsb],time1row6[msb-lst],....,time1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(X.size(1)):  # time step\n",
    "    for j in range(X.size(0)): # row #\n",
    "        X_bin = '{0:04b}'.format(int(X[15-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(X_bin[k])        \n",
    "#         file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ace7d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 9])\n"
     ]
    }
   ],
   "source": [
    "weight_int.size() # 8, 16 , 3, 3\n",
    "W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n",
    "print(W.size()) # 8, 16, 9\n",
    "\n",
    "bit_precision = 4\n",
    "file = open('weight.txt', 'w') #write to file\n",
    "file.write('#col0row15[msb-lsb],col0row6[msb-lst],....,col0row0[msb-lst]#\\n')\n",
    "file.write('#col1row15[msb-lsb],col1row6[msb-lst],....,col1row0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "\n",
    "W_temp=0\n",
    "for kij in range(9):\n",
    "    for i in range(W.size(0)):  # Column #\n",
    "        for j in range(W.size(1)): # row #\n",
    "            #W_bin = '{0:04b}'.format(int(W[i,7-j].item()+0.001))\n",
    "            if (W[i,15-j,kij].item()<0):\n",
    "                W_temp=W[i,15-j,kij].item()+(2**bit_precision)\n",
    "            else:\n",
    "                W_temp=W[i,15-j,kij].item()\n",
    "            W_bin = '{0:04b}'.format(int(W_temp+0.001))\n",
    "            for k in range(bit_precision):\n",
    "                file.write(str(W_bin[k]))        \n",
    "#             file.write(' ')  # for visibility with blank between words, you can use\n",
    "        file.write('\\n')\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7dc2dd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.,  0., -2., -2.,  1., -4.,  3.,  3., -3.,  3., -1., -4., -1.,  2.,\n",
       "         2., -4.], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_int.size()\n",
    "W = torch.reshape(weight_int, (weight_int.size(0), weight_int.size(1), -1))\n",
    "W.size()\n",
    "W[0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2a472ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_int.size()\n",
    "O = output_int[0]\n",
    "O = torch.reshape(O, (O.size(0), -1))\n",
    "O.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b950b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Complete this cell ###\n",
    "\n",
    "bit_precision = 16\n",
    "file = open('psum.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(O.size(1)):  # time step\n",
    "    for j in range(O.size(0)): # Column #\n",
    "        if (O[7-j,i].item()<0):\n",
    "            O_temp=O[7-j,i].item()+(2**bit_precision)\n",
    "        else:\n",
    "            O_temp=O[7-j,i].item()\n",
    "        O_bin = '{0:016b}'.format(int(O_temp+0.001))\n",
    "#         O_bin = str(int(O_temp+0.001))\n",
    "        #psum_tile_bin = '{0:016b}'.format(int(psum_tile[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(O_bin[k])\n",
    "#         file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d3ed976",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_precision = 16\n",
    "file = open('output.txt', 'w') #write to file\n",
    "file.write('#time0col7[msb-lsb],time0col6[msb-lst],....,time0col0[msb-lst]#\\n')\n",
    "file.write('#time1col7[msb-lsb],time1col6[msb-lst],....,time1col0[msb-lst]#\\n')\n",
    "file.write('#................#\\n')\n",
    "\n",
    "for i in range(O.size(1)):  # time step\n",
    "    for j in range(O.size(0)): # Column #\n",
    "        if (O[7-j,i].item()<0):\n",
    "            #O_temp=O[7-j,i].item()+(2**bit_precision)\n",
    "            O_temp=0\n",
    "        else:\n",
    "            O_temp=O[7-j,i].item()\n",
    "        O_bin = '{0:016b}'.format(int(O_temp+0.001))\n",
    "#         O_bin = str(int(O_temp+0.001))\n",
    "        #psum_tile_bin = '{0:016b}'.format(int(psum_tile[7-j,i].item()+0.001))\n",
    "        for k in range(bit_precision):\n",
    "            file.write(O_bin[k])\n",
    "#         file.write(' ')  # for visibility with blank between words, you can use\n",
    "    file.write('\\n')\n",
    "file.close() #close file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5929d34f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b32e11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624e080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a117d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
