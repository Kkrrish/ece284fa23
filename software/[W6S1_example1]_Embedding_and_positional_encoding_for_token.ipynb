{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-wallet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "\n",
    "embed_size = 4 # each word is represented with length 4 vector\n",
    "my_embedding = nn.Embedding(10, embed_size) # 10 words are supported. each word is mapped on either number 0 - 9\n",
    "\n",
    "input = torch.IntTensor([[1,2,4,5,5,5],\n",
    "                         [4,3,0,9,9,9]]) # two sentences with sequence length of 6\n",
    "                                                        # elements shoudl be integer\n",
    "embedded_input = my_embedding(input)\n",
    "print(embedded_input.size())\n",
    "print(\"embedding for 4th token (5) is:\", embedded_input[0, 3, :].element())\n",
    "print(\"embedding for 5th token (5) is:\", embedded_input[0, 4, :].element())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beautiful-league",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-fcb43c9d3321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m input = torch.LongTensor([[1,2,4,5,6,7],\n\u001b[1;32m      2\u001b[0m                          [4,3,0,9,10,11]]) # does not work as we cover up to 10\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membedded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "input = torch.LongTensor([[1,2,4,5,6,7],\n",
    "                         [4,3,0,9,10,11]]) # does not work as we cover up to 10\n",
    "embedded_input = my_embedding(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accepted-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)   # d_model: vector length of input \n",
    "        position = torch.arange(0, max_len).unsqueeze(1) # arrange: return 1D tensor from a to b-1\n",
    "        #print(position.size())  # torch.Size([5000, 1])\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model))\n",
    "        #print(div_term)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term) # ::2 means every other\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        #print(pe.size())      # torch.Size([5000, 4])\n",
    "        pe = pe.unsqueeze(0)  \n",
    "        #print(pe.size())      # torch.Size([1, 5000, 4]) <- the first dim will be # of sentences in input\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "white-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "      \n",
    "pe = PositionalEncoding(embed_size, 0)  # d_model: vector length of input (12 based on previous cells)\n",
    "#pe_pure = pe.forward(Variable(torch.zeros(batch_size,10, embed_size))) # send zero vector to see the pure positional encoding part\n",
    "embedded_input_w_pe = pe.forward(embedded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "scenic-surfing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-5.7126e-01,  2.8596e-01,  6.1990e-01,  4.9004e-02],\n",
      "         [-1.5105e+00,  4.4296e-01, -1.2973e+00, -3.7072e-01],\n",
      "         [ 9.0008e-01, -1.5065e-03, -1.8334e+00, -4.3780e-01],\n",
      "         [-7.3055e-01, -5.2499e-01, -1.3492e+00, -1.3128e+00],\n",
      "         [-7.3055e-01, -5.2499e-01, -1.3492e+00, -1.3128e+00],\n",
      "         [-7.3055e-01, -5.2499e-01, -1.3492e+00, -1.3128e+00]],\n",
      "\n",
      "        [[ 9.0008e-01, -1.5065e-03, -1.8334e+00, -4.3780e-01],\n",
      "         [-4.8804e-01, -1.0614e-01, -1.1204e+00,  1.2158e+00],\n",
      "         [ 1.0974e+00, -5.8310e-01, -9.4776e-01,  2.4841e-01],\n",
      "         [-4.6786e-02, -8.3433e-01, -8.2454e-01, -1.6718e+00],\n",
      "         [-4.6786e-02, -8.3433e-01, -8.2454e-01, -1.6718e+00],\n",
      "         [-4.6786e-02, -8.3433e-01, -8.2454e-01, -1.6718e+00]]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "tensor([[[-0.5713,  1.2860,  0.6199,  1.0490],\n",
      "         [-0.6690,  0.9833, -1.2873,  0.6292],\n",
      "         [ 1.8094, -0.4177, -1.8134,  0.5620],\n",
      "         [-0.5894, -1.5150, -1.3192, -0.3133],\n",
      "         [-1.4874, -1.1786, -1.3092, -0.3136],\n",
      "         [-1.6895, -0.2413, -1.2992, -0.3141]],\n",
      "\n",
      "        [[ 0.9001,  0.9985, -1.8334,  0.5622],\n",
      "         [ 0.3534,  0.4342, -1.1104,  2.2157],\n",
      "         [ 2.0067, -0.9992, -0.9278,  1.2482],\n",
      "         [ 0.0943, -1.8243, -0.7945, -0.6722],\n",
      "         [-0.8036, -1.4880, -0.7846, -0.6726],\n",
      "         [-1.0057, -0.5507, -0.7746, -0.6730]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedded_input)\n",
    "print(embedded_input_w_pe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "q[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-tobacco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-mainstream",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-crazy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-alias",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-suicide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-toilet",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disabled-cleanup",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-finger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-produce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-custody",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
